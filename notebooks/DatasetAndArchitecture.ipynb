{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jason\\new magang\\DUCK-Net\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 352\n",
    "img_width = 352\n",
    "\n",
    "image_path = \"C:\\\\jason\\\\new magang\\\\DUCK-Net\\\\kvasir\\\\images\\\\cju887ftknop008177nnjt46y.jpg\"\n",
    "mask_path = image_path.replace(\"images\", \"masks\")\n",
    "\n",
    "image = imread(image_path)\n",
    "mask_ = imread(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((1, img_height, img_width, 3), dtype=np.float32)\n",
    "Y_train = np.zeros((1, img_height, img_width), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros((img_height, img_width), dtype=np.bool_)\n",
    "\n",
    "pillow_image = Image.fromarray(image)\n",
    "\n",
    "pillow_image = pillow_image.resize((img_height, img_width))\n",
    "image = np.array(pillow_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = image / 255\n",
    "\n",
    "pillow_mask = Image.fromarray(mask_)\n",
    "pillow_mask = pillow_mask.resize((img_height, img_width), resample=Image.LANCZOS)\n",
    "mask_ = np.array(pillow_mask)\n",
    "mask_ = np.mean(mask_, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img_height):\n",
    "    for j in range(img_width):\n",
    "        if mask_[i, j] >= 127:\n",
    "                    mask[i, j] = 1\n",
    "\n",
    "Y_train = mask\n",
    "Y_train = np.expand_dims(Y_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.astype(\"uint8\")\n",
    "plt.imshow(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Custom Convolutional Layer of DUCK-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\jason\\new magang\\DUCK-Net\\CustomLayers\n",
      "_______________________________\n",
      "Output shape: torch.Size([1, 128, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "pathNow = os.path.abspath(os.path.join(os.path.dirname('__file__'), '../CustomLayers'))\n",
    "print(pathNow)\n",
    "if pathNow not in sys.path:\n",
    "    sys.path.append(pathNow)\n",
    "print('_______________________________')\n",
    "\n",
    "from PyTorchConvBlock2D import ConvBlock2D\n",
    "\n",
    "input_channels = 3\n",
    "starting_filters = 64\n",
    "\n",
    "# Instantiate the ConvBlock2D with filters 64 and block type 'duckv2'\n",
    "conv_block = ConvBlock2D(input_channels, starting_filters, 'duckv2', repeat=2)\n",
    "conv_block2 = ConvBlock2D(starting_filters, starting_filters*2, 'duckv2', repeat=2)\n",
    "\n",
    "# Create a random input tensor with shape (batch_size, channels, height, width)\n",
    "# Assuming channels are 64 to match the filters in the ConvBlock2D\n",
    "input_tensor = torch.randn(1, 3, 256, 256)  # Example with batch_size=1, channels=64, height=32, width=32\n",
    "\n",
    "# Pass the input tensor through the module\n",
    "output_tensor = conv_block(input_tensor)\n",
    "output_tensor = conv_block2(output_tensor)\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing DUCK-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor shape: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PyTorchConvBlock2D import ConvBlock2D\n",
    "\n",
    "class DuckNet(nn.Module):\n",
    "    def __init__(self, img_height, img_width, input_channels, out_classes, starting_filters):\n",
    "        super(DuckNet, self).__init__()\n",
    "\n",
    "        self.starting_filters = starting_filters\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, starting_filters * 2, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(starting_filters * 2, starting_filters * 4, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(starting_filters * 4, starting_filters * 8, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv2d(starting_filters * 8, starting_filters * 16, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv2d(starting_filters * 16, starting_filters * 32, kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.t0 = ConvBlock2D(input_channels, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l1i = nn.Conv2d(starting_filters, starting_filters * 2, kernel_size=2, stride=2, padding=0)\n",
    "        self.t1 = ConvBlock2D(starting_filters * 2, starting_filters * 2, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l2i = nn.Conv2d(starting_filters * 2, starting_filters * 4, kernel_size=2, stride=2, padding=0)\n",
    "        self.t2 = ConvBlock2D(starting_filters * 4, starting_filters * 4, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l3i = nn.Conv2d(starting_filters * 4, starting_filters * 8, kernel_size=2, stride=2, padding=0)\n",
    "        self.t3 = ConvBlock2D(starting_filters * 8, starting_filters * 8, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l4i = nn.Conv2d(starting_filters * 8, starting_filters * 16, kernel_size=2, stride=2, padding=0)\n",
    "        self.t4 = ConvBlock2D(starting_filters * 16, starting_filters * 16, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l5i = nn.Conv2d(starting_filters * 16, starting_filters * 32, kernel_size=2, stride=2, padding=0)\n",
    "        self.t51 = ConvBlock2D(starting_filters * 32, starting_filters * 32, 'resnet', repeat=2)\n",
    "        self.t53 = ConvBlock2D(starting_filters * 32, starting_filters * 16, 'resnet', repeat=2)\n",
    "\n",
    "        self.l5o = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c4 = ConvBlock2D(starting_filters * 16, starting_filters * 8, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l4o = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c3 = ConvBlock2D(starting_filters * 8, starting_filters * 4, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l3o = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c2 = ConvBlock2D(starting_filters * 4, starting_filters * 2, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l2o = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c1 = ConvBlock2D(starting_filters * 2, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "        self.l1o = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.c0 = ConvBlock2D(starting_filters, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "        self.output = nn.Conv2d(starting_filters, out_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = self.conv1(x)\n",
    "        p2 = self.conv2(p1)\n",
    "        p3 = self.conv3(p2)\n",
    "        p4 = self.conv4(p3)\n",
    "        p5 = self.conv5(p4)\n",
    "\n",
    "        t0 = self.t0(x)\n",
    "\n",
    "        l1i = self.l1i(t0)\n",
    "        s1 = l1i + p1\n",
    "        t1 = self.t1(s1)\n",
    "\n",
    "        l2i = self.l2i(t1)\n",
    "        s2 = l2i + p2\n",
    "        t2 = self.t2(s2)\n",
    "\n",
    "        l3i = self.l3i(t2)\n",
    "        s3 = l3i + p3\n",
    "        t3 = self.t3(s3)\n",
    "\n",
    "        l4i = self.l4i(t3)\n",
    "        s4 = l4i + p4\n",
    "        t4 = self.t4(s4)\n",
    "\n",
    "        l5i = self.l5i(t4)\n",
    "        s5 = l5i + p5\n",
    "        t51 = self.t51(s5)\n",
    "        t53 = self.t53(t51)\n",
    "\n",
    "        l5o = self.l5o(t53)\n",
    "        c4 = l5o + t4\n",
    "        q4 = self.c4(c4)\n",
    "\n",
    "        l4o = self.l4o(q4)\n",
    "        c3 = l4o + t3\n",
    "        q3 = self.c3(c3)\n",
    "\n",
    "        l3o = self.l3o(q3)\n",
    "        c2 = l3o + t2\n",
    "        q6 = self.c2(c2)\n",
    "\n",
    "        l2o = self.l2o(q6)\n",
    "        c1 = l2o + t1\n",
    "        q1 = self.c1(c1)\n",
    "\n",
    "        l1o = self.l1o(q1)\n",
    "        c0 = l1o + t0\n",
    "        z1 = self.c0(c0)\n",
    "\n",
    "        output = self.output(z1)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Instantiate the model\n",
    "img_height=256\n",
    "img_width = 256 \n",
    "input_channels = 3\n",
    "out_classes=1\n",
    "starting_filters = 64\n",
    "\n",
    "model = DuckNet(img_height, img_width, input_channels, out_classes, starting_filters)\n",
    "\n",
    "# Generate a random input tensor\n",
    "input_tensor = torch.randn(1, input_channels, img_height, img_width)\n",
    "\n",
    "# Forward pass\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(\"Output tensor shape:\", output_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
